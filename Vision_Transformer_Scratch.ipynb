{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0fyQsKBOYOqyfeoQzMV1/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Vitをゼロから実装する\n",
        "\n",
        "https://towardsdatascience.com/paper-walkthrough-vision-transformer-vit-c5dcf76f1a7a"
      ],
      "metadata": {
        "id": "4ozcW2gASac5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fivftsTIRZ1A",
        "outputId": "da25a72c-ca6d-40b6-98df-0f5d13538925"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要なライブラリをインストールする。\n",
        "`torchinfo`の`summary()`はモデルの詳細を可視化する。"
      ],
      "metadata": {
        "id": "J_kqXKRVS4E6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yOZA6dvKRHBv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パラメータの設定"
      ],
      "metadata": {
        "id": "qusRoXfDTGCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(1)\n",
        "BATCH_SIZE   = 1\n",
        "IMAGE_SIZE   = 224\n",
        "IN_CHANNELS  = 3\n",
        "\n",
        "#(2)\n",
        "PATCH_SIZE   = 16\n",
        "NUM_HEADS    = 12\n",
        "NUM_ENCODERS = 12\n",
        "EMBED_DIM    = 768\n",
        "MLP_SIZE     = EMBED_DIM * 4    # 768*4 = 3072\n",
        "\n",
        "#(3)\n",
        "NUM_PATCHES  = (IMAGE_SIZE//PATCH_SIZE) ** 2    # (224//16)**2 = 196\n",
        "\n",
        "#(4)\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_CLASSES  = 10"
      ],
      "metadata": {
        "id": "5sd6c-bzRHqK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "デバイスの選択。今回はGPUでなくても大丈夫"
      ],
      "metadata": {
        "id": "7voynUDKTSod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTBnu-AaRmGl",
        "outputId": "af1074cb-7c3a-4418-a6ef-a9d8150cfd3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatcherUnfold(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.unfold = nn.Unfold(kernel_size=PATCH_SIZE, stride=PATCH_SIZE)\n",
        "        self.linear_projection = nn.Linear(in_features=IN_CHANNELS*PATCH_SIZE*PATCH_SIZE,\n",
        "                                           out_features=EMBED_DIM)\n",
        "    def forward(self, x):\n",
        "        print(f'original\\t: {x.size()}')\n",
        "\n",
        "        x = self.unfold(x)\n",
        "        print(f'after unfold\\t: {x.size()}')\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "        print(f'after permute\\t: {x.size()}')\n",
        "\n",
        "        x = self.linear_projection(x)\n",
        "        print(f'after lin proj\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "tXxS1VQsRoEq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patcher_unfold = PatcherUnfold()\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "x = patcher_unfold(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKVok7VMRqm9",
        "outputId": "cefa7267-3ca2-4f32-89b8-53971c714219"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t: torch.Size([1, 3, 224, 224])\n",
            "after unfold\t: torch.Size([1, 768, 196])\n",
            "after permute\t: torch.Size([1, 196, 768])\n",
            "after lin proj\t: torch.Size([1, 196, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatcherConv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=IN_CHANNELS,\n",
        "                              out_channels=EMBED_DIM,\n",
        "                              kernel_size=PATCH_SIZE,\n",
        "                              stride=PATCH_SIZE)\n",
        "\n",
        "        self.flatten = nn.Flatten(start_dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f'original\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.conv(x)    #(1)\n",
        "        print(f'after conv\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.flatten(x)    #(2)\n",
        "        print(f'after flatten\\t\\t: {x.size()}')\n",
        "\n",
        "        x = x.permute(0, 2, 1)    #(3)\n",
        "        print(f'after permute\\t\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1QNx8JmCRske"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patcher_conv = PatcherConv()\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "x = patcher_conv(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7RxgwRERuR4",
        "outputId": "04982985-4758-4938-e5fd-71120100ef1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 3, 224, 224])\n",
            "after conv\t\t: torch.Size([1, 768, 14, 14])\n",
            "after flatten\t\t: torch.Size([1, 768, 196])\n",
            "after permute\t\t: torch.Size([1, 196, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PosEmbedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.class_token = nn.Parameter(torch.randn(size=(BATCH_SIZE, 1, EMBED_DIM)),\n",
        "                                        requires_grad=True)    #(1)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(size=(BATCH_SIZE, NUM_PATCHES+1, EMBED_DIM)),\n",
        "                                          requires_grad=True)    #(2)\n",
        "        self.dropout = nn.Dropout(p=DROPOUT_RATE)  #(3)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        class_token = self.class_token\n",
        "        print(f'class_token dim\\t\\t: {class_token.size()}')\n",
        "\n",
        "        print(f'before concat\\t\\t: {x.size()}')\n",
        "        x = torch.cat([class_token, x], dim=1)    #(1)\n",
        "        print(f'after concat\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.pos_embedding + x    #(2)\n",
        "        print(f'after pos_embedding\\t: {x.size()}')\n",
        "\n",
        "        x = self.dropout(x)    #(3)\n",
        "        print(f'after dropout\\t\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "JUDFkW3GRwOS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embedding = PosEmbedding()\n",
        "x = pos_embedding(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlMCF0TuRzvo",
        "outputId": "b85951af-5fba-4324-f218-9599f819df4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_token dim\t\t: torch.Size([1, 1, 768])\n",
            "before concat\t\t: torch.Size([1, 196, 768])\n",
            "after concat\t\t: torch.Size([1, 197, 768])\n",
            "after pos_embedding\t: torch.Size([1, 197, 768])\n",
            "after dropout\t\t: torch.Size([1, 197, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm_0 = nn.LayerNorm(EMBED_DIM)    #(1)\n",
        "\n",
        "        self.multihead_attention = nn.MultiheadAttention(EMBED_DIM,    #(2)\n",
        "                                                         num_heads=NUM_HEADS,\n",
        "                                                         batch_first=True,\n",
        "                                                         dropout=DROPOUT_RATE)\n",
        "\n",
        "        self.norm_1 = nn.LayerNorm(EMBED_DIM)    #(3)\n",
        "\n",
        "        self.mlp = nn.Sequential(    #(4)\n",
        "            nn.Linear(in_features=EMBED_DIM, out_features=MLP_SIZE),    #(5)\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(p=DROPOUT_RATE),\n",
        "            nn.Linear(in_features=MLP_SIZE, out_features=EMBED_DIM),    #(6)\n",
        "            nn.Dropout(p=DROPOUT_RATE)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        residual = x    #(1)\n",
        "        print(f'residual dim\\t\\t: {residual.size()}')\n",
        "\n",
        "        x = self.norm_0(x)    #(2)\n",
        "        print(f'after norm\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.multihead_attention(x, x, x)[0]    #(3)\n",
        "        print(f'after attention\\t\\t: {x.size()}')\n",
        "\n",
        "        x = x + residual    #(4)\n",
        "        print(f'after addition\\t\\t: {x.size()}')\n",
        "\n",
        "        residual = x    #(5)\n",
        "        print(f'residual dim\\t\\t: {residual.size()}')\n",
        "\n",
        "        x = self.norm_1(x)    #(6)\n",
        "        print(f'after norm\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.mlp(x)    #(7)\n",
        "        print(f'after mlp\\t\\t: {x.size()}')\n",
        "\n",
        "        x = x + residual    #(8)\n",
        "        print(f'after addition\\t\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1hKBlIieR1uQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_encoder = TransformerEncoder()\n",
        "x = transformer_encoder(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8as0s_s4R8NF",
        "outputId": "7f382fe1-1466-4905-8be1-e82e4f5caea4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.LayerNorm(EMBED_DIM)\n",
        "        self.linear_0 = nn.Linear(in_features=EMBED_DIM,\n",
        "                                  out_features=EMBED_DIM)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.linear_1 = nn.Linear(in_features=EMBED_DIM,\n",
        "                                  out_features=NUM_CLASSES)    #(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f'original\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.norm(x)\n",
        "        print(f'after norm\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.linear_0(x)\n",
        "        print(f'after layer_0 mlp\\t: {x.size()}')\n",
        "\n",
        "        x = self.gelu(x)\n",
        "        print(f'after gelu\\t\\t: {x.size()}')\n",
        "\n",
        "        x = self.linear_1(x)\n",
        "        print(f'after layer_1 mlp\\t: {x.size()}')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "QmBA04w0R-Ee"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x[:, 0]    #(1)\n",
        "mlp_head = MLPHead()\n",
        "x = mlp_head(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaU5n5cHSAKQ",
        "outputId": "e0b41326-97e0-402f-cff4-8b899c8dfc7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 768])\n",
            "after norm\t\t: torch.Size([1, 768])\n",
            "after layer_0 mlp\t: torch.Size([1, 768])\n",
            "after gelu\t\t: torch.Size([1, 768])\n",
            "after layer_1 mlp\t: torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.patcher = PatcherUnfold()\n",
        "        self.patcher = PatcherConv()    #(1)\n",
        "        self.pos_embedding = PosEmbedding()\n",
        "        self.transformer_encoders = nn.Sequential(\n",
        "            *[TransformerEncoder() for _ in range(NUM_ENCODERS)]    #(2)\n",
        "            )\n",
        "        self.mlp_head = MLPHead()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.patcher(x)\n",
        "        x = self.pos_embedding(x)\n",
        "        x = self.transformer_encoders(x)\n",
        "        x = x[:, 0]    #(3)\n",
        "        x = self.mlp_head(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "bklllSynSBi5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit = ViT().to(device)\n",
        "x = torch.randn(1, 3, 224, 224).to(device)\n",
        "print(vit(x).size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh_k5bb_SDcU",
        "outputId": "25893490-8069-401f-8b0a-76249c8d94d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 3, 224, 224])\n",
            "after conv\t\t: torch.Size([1, 768, 14, 14])\n",
            "after flatten\t\t: torch.Size([1, 768, 196])\n",
            "after permute\t\t: torch.Size([1, 196, 768])\n",
            "class_token dim\t\t: torch.Size([1, 1, 768])\n",
            "before concat\t\t: torch.Size([1, 196, 768])\n",
            "after concat\t\t: torch.Size([1, 197, 768])\n",
            "after pos_embedding\t: torch.Size([1, 197, 768])\n",
            "after dropout\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "original\t\t: torch.Size([1, 768])\n",
            "after norm\t\t: torch.Size([1, 768])\n",
            "after layer_0 mlp\t: torch.Size([1, 768])\n",
            "after gelu\t\t: torch.Size([1, 768])\n",
            "after layer_1 mlp\t: torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vit, input_size=(1,3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEVXP8PoSFF0",
        "outputId": "3e579a3a-fdb9-42ff-c8e1-fd0e8484b79e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original\t\t: torch.Size([1, 3, 224, 224])\n",
            "after conv\t\t: torch.Size([1, 768, 14, 14])\n",
            "after flatten\t\t: torch.Size([1, 768, 196])\n",
            "after permute\t\t: torch.Size([1, 196, 768])\n",
            "class_token dim\t\t: torch.Size([1, 1, 768])\n",
            "before concat\t\t: torch.Size([1, 196, 768])\n",
            "after concat\t\t: torch.Size([1, 197, 768])\n",
            "after pos_embedding\t: torch.Size([1, 197, 768])\n",
            "after dropout\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after attention\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "residual dim\t\t: torch.Size([1, 197, 768])\n",
            "after norm\t\t: torch.Size([1, 197, 768])\n",
            "after mlp\t\t: torch.Size([1, 197, 768])\n",
            "after addition\t\t: torch.Size([1, 197, 768])\n",
            "original\t\t: torch.Size([1, 768])\n",
            "after norm\t\t: torch.Size([1, 768])\n",
            "after layer_0 mlp\t: torch.Size([1, 768])\n",
            "after gelu\t\t: torch.Size([1, 768])\n",
            "after layer_1 mlp\t: torch.Size([1, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ViT                                      [1, 10]                   --\n",
              "├─PatcherConv: 1-1                       [1, 196, 768]             --\n",
              "│    └─Conv2d: 2-1                       [1, 768, 14, 14]          590,592\n",
              "│    └─Flatten: 2-2                      [1, 768, 196]             --\n",
              "├─PosEmbedding: 1-2                      [1, 197, 768]             152,064\n",
              "│    └─Dropout: 2-3                      [1, 197, 768]             --\n",
              "├─Sequential: 1-3                        [1, 197, 768]             --\n",
              "│    └─TransformerEncoder: 2-4           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-1               [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-2      [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-3               [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-4              [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-5           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-5               [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-6      [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-7               [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-8              [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-6           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-9               [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-10     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-11              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-12             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-7           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-13              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-14     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-15              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-16             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-8           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-17              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-18     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-19              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-20             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-9           [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-21              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-22     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-23              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-24             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-10          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-25              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-26     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-27              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-28             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-11          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-29              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-30     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-31              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-32             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-12          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-33              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-34     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-35              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-36             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-13          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-37              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-38     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-39              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-40             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-14          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-41              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-42     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-43              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-44             [1, 197, 768]             4,722,432\n",
              "│    └─TransformerEncoder: 2-15          [1, 197, 768]             --\n",
              "│    │    └─LayerNorm: 3-45              [1, 197, 768]             1,536\n",
              "│    │    └─MultiheadAttention: 3-46     [1, 197, 768]             2,362,368\n",
              "│    │    └─LayerNorm: 3-47              [1, 197, 768]             1,536\n",
              "│    │    └─Sequential: 3-48             [1, 197, 768]             4,722,432\n",
              "├─MLPHead: 1-4                           [1, 10]                   --\n",
              "│    └─LayerNorm: 2-16                   [1, 768]                  1,536\n",
              "│    └─Linear: 2-17                      [1, 768]                  590,592\n",
              "│    └─GELU: 2-18                        [1, 768]                  --\n",
              "│    └─Linear: 2-19                      [1, 10]                   7,690\n",
              "==========================================================================================\n",
              "Total params: 86,396,938\n",
              "Trainable params: 86,396,938\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 173.06\n",
              "==========================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 102.89\n",
              "Params size (MB): 231.59\n",
              "Estimated Total Size (MB): 335.08\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3wb1oZ3mSKjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}